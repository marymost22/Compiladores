12c12
< 	movsd	.LC0(%rip), %xmm1
---
> 	movsd	.LC0(%rip), %xmm0
14,17c14,17
< 	pxor	%xmm0, %xmm0
< 	cvtsi2sd	%eax, %xmm0
< 	mulsd	%xmm1, %xmm0
< 	movsd	%xmm0, res(,%rax,8)
---
> 	pxor	%xmm1, %xmm1
> 	cvtsi2sd	%eax, %xmm1
> 	mulsd	%xmm0, %xmm1
> 	movsd	%xmm1, res(,%rax,8)
19c19,54
< 	cmpq	$10000, %rax	
---
> 	pxor	%xmm2, %xmm2
> 	cvtsi2sd	%eax, %xmm2
> 	mulsd	%xmm0, %xmm2
> 	movsd	%xmm2, res(,%rax,8)
> 	leaq	1(%rax), %rcx
> 	pxor	%xmm3, %xmm3
> 	cvtsi2sd	%ecx, %xmm3
> 	mulsd	%xmm0, %xmm3
> 	movsd	%xmm3, res(,%rcx,8)
> 	leaq	2(%rax), %rsi
> 	pxor	%xmm4, %xmm4
> 	cvtsi2sd	%esi, %xmm4
> 	mulsd	%xmm0, %xmm4
> 	movsd	%xmm4, res(,%rsi,8)
> 	leaq	3(%rax), %rdi
> 	pxor	%xmm5, %xmm5
> 	cvtsi2sd	%edi, %xmm5
> 	mulsd	%xmm0, %xmm5
> 	movsd	%xmm5, res(,%rdi,8)
> 	leaq	4(%rax), %r8
> 	pxor	%xmm6, %xmm6
> 	cvtsi2sd	%r8d, %xmm6
> 	mulsd	%xmm0, %xmm6
> 	movsd	%xmm6, res(,%r8,8)
> 	leaq	5(%rax), %r9
> 	pxor	%xmm7, %xmm7
> 	cvtsi2sd	%r9d, %xmm7
> 	mulsd	%xmm0, %xmm7
> 	movsd	%xmm7, res(,%r9,8)
> 	leaq	6(%rax), %r10
> 	pxor	%xmm8, %xmm8
> 	cvtsi2sd	%r10d, %xmm8
> 	mulsd	%xmm0, %xmm8
> 	movsd	%xmm8, res(,%r10,8)
> 	addq	$7, %rax
> 	cmpq	$10000, %rax
21,25c56,60
< 	movl	$res, %eax	
< 	movl	$res+80000, %ecx
< 	movsd	.LC1(%rip), %xmm2
< 	movsd	.LC2(%rip), %xmm4
< 	movsd	.LC0(%rip), %xmm3
---
> 	movl	$res, %edx
> 	movl	$res+80000, %r11d
> 	movsd	.LC1(%rip), %xmm9
> 	movsd	.LC2(%rip), %xmm10
> 	movsd	.LC0(%rip), %xmm11
27,33c62,68
< 	movq	%rax, %rdx
< 	movsd	(%rax), %xmm0
< 	ucomisd	%xmm0, %xmm2
< 	jbe	.L10
< 	movapd	%xmm0, %xmm1
< 	mulsd	%xmm0, %xmm1
< 	addsd	%xmm3, %xmm1
---
> 	movq	%rdx, %rax
> 	movsd	(%rdx), %xmm12
> 	ucomisd	%xmm12, %xmm9
> 	jbe	.L31
> 	movapd	%xmm12, %xmm13
> 	mulsd	%xmm12, %xmm13
> 	addsd	%xmm11, %xmm13
35,37c70,72
< .L10:
< 	movapd	%xmm0, %xmm1
< 	subsd	%xmm4, %xmm1
---
> .L31:
> 	movapd	%xmm12, %xmm13
> 	subsd	%xmm10, %xmm13
39,44c74,81
< 	addsd	%xmm1, %xmm0
< 	movsd	%xmm0, (%rdx)
< 	addq	$8, %rax
< 	cmpq	%rcx, %rax
< 	jne	.L6
< 	subq	$8, %rsp
---
> 	addsd	%xmm13, %xmm12
> 	movsd	%xmm12, (%rax)
> 	leaq	8(%rdx), %rcx
> 	movsd	8(%rdx), %xmm14
> 	ucomisd	%xmm14, %xmm9
> 	ja	.L10
> 	jmp	.L32
> .L40:
54a92,186
> .L32:
> 	movapd	%xmm14, %xmm15
> 	subsd	%xmm10, %xmm15
> 	jmp	.L33
> .L10:
> 	movapd	%xmm14, %xmm15
> 	mulsd	%xmm14, %xmm15
> 	addsd	%xmm11, %xmm15
> .L33:
> 	addsd	%xmm15, %xmm14
> 	movsd	%xmm14, (%rcx)
> 	movsd	8(%rcx), %xmm0
> 	ucomisd	%xmm0, %xmm9
> 	ja	.L12
> 	movapd	%xmm0, %xmm1
> 	subsd	%xmm10, %xmm1
> 	jmp	.L34
> .L12:
> 	movapd	%xmm0, %xmm1
> 	mulsd	%xmm0, %xmm1
> 	addsd	%xmm11, %xmm1
> .L34:
> 	addsd	%xmm1, %xmm0
> 	movsd	%xmm0, 8(%rcx)
> 	movsd	16(%rcx), %xmm2
> 	ucomisd	%xmm2, %xmm9
> 	ja	.L14
> 	movapd	%xmm2, %xmm3
> 	subsd	%xmm10, %xmm3
> 	jmp	.L35
> .L14:
> 	movapd	%xmm2, %xmm3
> 	mulsd	%xmm2, %xmm3
> 	addsd	%xmm11, %xmm3
> .L35:
> 	addsd	%xmm3, %xmm2
> 	movsd	%xmm2, 16(%rcx)
> 	movsd	24(%rcx), %xmm5
> 	ucomisd	%xmm5, %xmm9
> 	ja	.L16
> 	movapd	%xmm5, %xmm4
> 	subsd	%xmm10, %xmm4
> 	jmp	.L36
> .L16:
> 	movapd	%xmm5, %xmm4
> 	mulsd	%xmm5, %xmm4
> 	addsd	%xmm11, %xmm4
> .L36:
> 	addsd	%xmm4, %xmm5
> 	movsd	%xmm5, 24(%rcx)
> 	movsd	32(%rcx), %xmm6
> 	ucomisd	%xmm6, %xmm9
> 	ja	.L18
> 	movapd	%xmm6, %xmm7
> 	subsd	%xmm10, %xmm7
> 	jmp	.L37
> .L18:
> 	movapd	%xmm6, %xmm7
> 	mulsd	%xmm6, %xmm7
> 	addsd	%xmm11, %xmm7
> .L37:
> 	addsd	%xmm7, %xmm6
> 	movsd	%xmm6, 32(%rcx)
> 	movsd	40(%rcx), %xmm8
> 	ucomisd	%xmm8, %xmm9
> 	ja	.L20
> 	movapd	%xmm8, %xmm12
> 	subsd	%xmm10, %xmm12
> 	jmp	.L38
> .L20:
> 	movapd	%xmm8, %xmm12
> 	mulsd	%xmm8, %xmm12
> 	addsd	%xmm11, %xmm12
> .L38:
> 	addsd	%xmm12, %xmm8
> 	movsd	%xmm8, 40(%rcx)
> 	movsd	48(%rcx), %xmm13
> 	ucomisd	%xmm13, %xmm9
> 	ja	.L22
> 	movapd	%xmm13, %xmm14
> 	subsd	%xmm10, %xmm14
> 	jmp	.L39
> .L22:
> 	movapd	%xmm13, %xmm14
> 	mulsd	%xmm13, %xmm14
> 	addsd	%xmm11, %xmm14
> .L39:
> 	addsd	%xmm14, %xmm13
> 	movsd	%xmm13, 48(%rcx)
> 	leaq	56(%rcx), %rdx
> 	cmpq	%r11, %rdx
> 	jne	.L6
> 	subq	$8, %rsp
> 	.cfi_def_cfa_offset 16
> 	jmp	.L40
